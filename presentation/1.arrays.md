# Systems-level Dependently-typed Array programming language
_All exercises up to this point were pale imitations of the abyss that now lies ahead_
## Core Goals
* Capture as many forms of genericity as possible
* The front language should be natural/intuitive

## Definition of Done
1. Fuse every unboxed Tensor operation
2. Support product types
3. Sum types

## Lens' get,set and traverse are array functions
lenses: get, set and traverse are list operations, so what stops us from simply using our list infrastructure ? well in haskell one has to rely on simulating subtyping and template-haskell to be able to function on product types/tuples

The ideal solution requires flexible typevariables and covariant subsumption in type constructors, the point being we need product types to subsume arrays, so, eg. (Int , String) is a valid [a]

Lens.Prism: or how to handle sumtypes ? prisms return 'Maybe a', since the shape of a recursive sumtype is irregular, especially in the presence of recursive data, which represents seperate functionality to handle sumtypes (crucially for this sumtypes must be typed as polytypes: AltTy1 | AltTy2 .. , both for prisms and for subtyping in general)

## Array Oriented
Array Oriented programming involves generalizing operations over Tensors (shaped arrays):
```J
NB. in J
0 1 + 1 = 1 2
1 2 + 2 1 = 3 3 3
```
Some typed examples

```haskell
-- normal zip vs. join at rank 1 (sometimes called 'stitch')
zip : [a] -> [b] -> [(a,b)]
(,) : [a] -> [a] -> [[a,a]] -- note. (,) takes lists, so it's rank = 1 1

-- Array oriented zipWith
zipWith : (a->b->c) -> [a] -> [b] -> [c]
zipWith f a b = (fold f [] @ _1) (a , b)  -- (a,b) has type [a]
```
It's still an open question whether functions should automatically find agreement like this. In any event it could be toggled by importing Tensor overloads for (+) etc.. Concretely, a 'match' function is needed to handle agreement.
### Agreement
Array languages usually only offer functions of arity 1 or 2 (Monad/Dyad verbs in J terminology)
1. split the arrays into macro-cells according to the rank of the verb - the remaining shape is called the 'frame' of the argument. So for verbs of rank 0 0, the frames are simply the shape of each argument
2. the frames must match identically for the entire length of the shorter frame.
3. We must account for the surplus frame: by looping over it and executing the verb on all macrocells.

```haskell
-- match implements this logic, for use in overloads on tensors, eg. (+) (-) etc..
-- match assumes step 1. has been done (it doesn't know the verb's rank); it handles agreement of surplus frames
type Shape = [Nat]
match1 : (x->y) -> Shape -> (a->b)
match2 : (x->y->z) -> Shape -> Shape -> (a->b->c)
matchn -- unclear complications, but notice a direct link to zipWithN

-- modify rank
(@) : (a->b) -> n=Nat -> (a->b)
-- A more generic version should take a [Nat], one for each argument
```
At this point we're led towards arity-genericity, for matchn and (@). It's worth noting that zipwithN is matchN at rank 1

## Fold-Build
```haskell
buildRavel = (,) [] -- where (,) is similar to haskell (:)
--eg.
map f xs = build (\c n -> foldr (c << f) n xs)
sum = foldr (+) 0
down m = build (\c n -> letrec loop x = if x<=0 then n else c x (loop (x-1)))
-- then
sum $ map (^2) (down z)
= foldr (+) 0 $ build (\c n -> foldr (c << (^2)) n (down z))
= foldr ((+) << (^2)) 0 (down z)
= letrec loop x = if x<=0 then 0 else x^2 + loop (x-1) in loop z
-- which could even be reworked into a tail call by the optimizer (gcc is able to do so even with no purity guarantees)
```
Tensor Fusion: To achieve fusion at any rank, we need the folds to match the builds. If we always fold along the ravel, we lose useful information. The most sensible plan then, is to define several builds, with the idea to exploit the additional information, and the understanding that in all cases we can fallback to a buildRavel. A couple of important notes:
* build is not an everyday programmer function, so we can bend it to suit our optimization purposes
* ideal builds are those we can fold in many different ways
* Before or after typechecking? Fusion shouldn't interfere with typechecking errors, so we can either have the compiler recognize folds, do it in the statically typed Core language (not fun) or have tc errors be language primitives
```haskell

-- buildRavel (requires a foldr)
buildList g      = g (,) []
foldr k z (buildList g) = g k z

-- indexed build is ideal, it supports any fold at any rank easily:
buildI : Nat -> (Int -> a)
buildI n fI      = fI @0 [0..n]

-- An additional benefit is seen in operations like `1 4 5 0 ! (buildIShape f)`
buildIShape [Nat] -> (Int -> a)
buildIShape n atI = n `shape` (buildI [0..] atI)
```

What about building matrices .. Tensors ?
```haskell
-- Obvious way is to call buildList in a buildList
buildList g : [[a]] -- g is passing arrays to cons
(,) : a -> [a] -> [a]
(,) : [a] -> [[a]] -> [[a]] -- each Cons operation is also calling a build
-- The problem with this is it is very rigid - we cannot transform it easily, and it only fuses with foldr@1

```

## Arity and Tensors
There is a known pattern in the functions: repeat, map, zipWith, zipWith3, zipWithN, They are known to be doubly-generic. I have also noted that zipWithN is exactly matchN @ 1, so matchN is in fact even more general.

```haskell
type Arrow (t:Type) = Stack (->) t -- Arrows are stacks of at least one type, using the (->) type constructor
-- The compiler should recognize Arrow stacks rather than (->) when type judging.
```

## Effects
Either
 - effects are compiler primitives 
 - or typecheck errors are available as language primitives

The second option is my preferred one, since in any case we often want to craft custom typecheck errors, mainly to ignore some type refinement information
```haskell
-- normal type for main
type IO = In & Out
main : [String] -> Byte % IO
main = print (readDir pwd ! 1)

```
Unlike Frank, We cannot afford to define an order of operations for function arguments: we would no longer be free to multithread nor rearrange arguments: (eg. if only one function wants to inplace a data, then we should call it last and let it do so)

What is the type of an Effect ? Pretty much a product polytype (&), similar, but more flexible than a haskell constraint. Ultimately stateful effects need to become monads, after which the question becomes how to insert <$> <*> >>= (we don't want effects to be a compiler speciality, that indicates a failure of the type system).
* Some monads' (>>=) are distributive over composition, but not all (Maybe)
```haskell

-- type constructor for effectful functions
data Eff = Eff Effect a
data (fn:Type) % (ef : Effect) = Eff ef fn
(;) : Eff ef f -> Eff eg g -> Eff (ef & eg) g
```
